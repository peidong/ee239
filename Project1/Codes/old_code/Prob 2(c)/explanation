Now use a neural network regression model. Explain the major parameters of your model and how they affect your performance in RMSE.

I used the pybrain library (one of the most commonly used for neural network in Python) to implement my neural network regression model. As a result of the 10-fold cross validation, the best Root Mean Squared Error (RMSE) I can get is 0.118428240362.

The major parameters of my neural network model are the number of hidden nodes, the number of hidden layers and the learning rate. Picking a correct number for hidden layers and a correct number for the number of nodes in the hidden layer is very important. The introduction of hidden layer(s) makes it possible for the network to perform non-linear regression, but higher dimensionalities of the hidden layers are prone to overfitting. In order to secure the ability of the network to generalize and predict, the number of hidden nodes has to be kept as low as possible, otherwise my model will not perform well on data that are not part of the training set. Having a optimal learning rate is also important, because too low a learning rate may cause the neural network to be stuck in local minima, and too high a learning rate may cause it to not converge at all.

With the help of the 10-fold cross validation, I tuned these parameters and chose the number of hidden nodes and layers that gives the lowest RMSE. Having 2 hidden layers (0.118428240362) gave me lower RMSE than having 1 hidden layer (0.141693085531) and 3 hidden layers (0.122700481986); Having 10 hidden nodes gave me the best RMSE (0.118428240362), compared to having 7 hidden nodes (0.132536116187) and having 15 hidden nodes (0.14289441).
