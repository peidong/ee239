{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '20news-bydate-train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-df8337da1006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#plot the histogram for 20 topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20news-bydate-train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mdir_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'20news-bydate-train/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mcount1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '20news-bydate-train'"
     ]
    }
   ],
   "source": [
    "# from matplotlib import pyplot\n",
    "import os\n",
    "\n",
    "#define a function to count the document number \n",
    "def Count(dirname):\n",
    "  count=0\n",
    "  for item in os.listdir(dirname):\n",
    "    count+=1\n",
    "  return count\n",
    "\n",
    "counter=[]\n",
    "\n",
    "#plot the histogram for 20 topics\n",
    "for dir in os.listdir('20news-bydate-train'):\n",
    "  dir_name='20news-bydate-train/'+dir\n",
    "  count1=Count(dir_name)\n",
    "  counter.append(count1)\n",
    "\n",
    "i=0;\n",
    "\n",
    "for dir in os.listdir('20news-bydate-test'):\n",
    "  #print counter[i],'\\n'\n",
    "  dir_name='20news-bydate-test/'+dir\n",
    "  count2=Count(dir_name)\n",
    "  counter[i]+=count2\n",
    "  #print counter[i],'\\n'\n",
    "  i+=1\n",
    "  \n",
    "#count the document number for the two groups\n",
    "new_counter=[0,0]\n",
    "for dir in os.listdir('20news-bydate-train'):\n",
    "  if(dir=='comp.graphics' or dir=='comp.os.ms-windows.misc' or dir=='comp.sys.ibm.pc.hardware' or dir=='comp.sys.mac.hardware'):\n",
    "    dir_name='20news-bydate-train/'+dir\n",
    "    count1=Count(dir_name)\n",
    "    new_counter[0]+=count1\n",
    "    #print (new_counter[0],'\\n')\n",
    "  if(dir=='rec.autos' or dir=='rec.motorcycles' or dir=='rec.sport.baseball' or dir=='rec.sport.hockey'):\n",
    "    dir_name='20news-bydate-train/'+dir\n",
    "    count1=Count(dir_name)\n",
    "    new_counter[1]+=count1\n",
    "    #print (new_counter[1],'\\n')\n",
    "    \n",
    "for dir in os.listdir('20news-bydate-test'):\n",
    "  if(dir=='comp.graphics' or dir=='comp.os.ms-windows.misc' or dir=='comp.sys.ibm.pc.hardware' or dir=='comp.sys.mac.hardware'):\n",
    "    dir_name='20news-bydate-test/'+dir\n",
    "    count2=Count(dir_name)\n",
    "    new_counter[0]+=count2\n",
    "    #print (new_counter[0],'\\n')\n",
    "  if(dir=='rec.autos' or dir=='rec.motorcycles' or dir=='rec.sport.baseball' or dir=='rec.sport.hockey'):\n",
    "    dir_name='20news-bydate-test/'+dir\n",
    "    count2=Count(dir_name)\n",
    "    new_counter[1]+=count2\n",
    "    #print (new_counter[1],'\\n')\n",
    "\n",
    "print ('Group1 is: ',new_counter[0],', Group2 is: ',new_counter[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "n = 20\n",
    "values = (counter[0],counter[1],counter[2],counter[3],counter[4],counter[5],counter[6],counter[7],counter[8],counter[9],counter[10],counter[11],counter[12],counter[13],counter[14],counter[15],counter[16],counter[17],counter[18],counter[19])\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.35\n",
    "opacity = 1.0\n",
    "bars = plt.bar(index, values, bar_width,alpha = opacity, color = 'b')\n",
    "plt.xlabel('Topics')\n",
    "plt.xlabel('Documents')\n",
    "plt.title('Number of documents per topic')\n",
    "plt.xticks(index + bar_width, ('1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20'))\n",
    "plt.ylim(0,1000)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 114729)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "import re\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "all_data = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TFxIDF = TfidfVectorizer(analyzer='word',stop_words=stop_words,token_pattern='[a-zA-Z]{2,}',)\n",
    "TFxIDF_data = TFxIDF.fit_transform(all_data.data)\n",
    "count = TFxIDF_data.shape\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lines', 'com', 'scsi', 'ide', 'subject', 'drive', 'edu', 'card', 'organization', 'mb'])\n",
      "dict_keys(['mac', 'apple', 'lines', 'posting', 'university', 'nntp', 'subject', 'edu', 'com', 'organization'])\n",
      "dict_keys(['new', 'sale', 'lines', 'posting', 'university', 'com', 'host', 'subject', 'edu', 'organization'])\n",
      "dict_keys(['lines', 'church', 'god', 'jesus', 'know', 'people', 'subject', 'edu', 'think', 'organization'])\n"
     ]
    }
   ],
   "source": [
    "list=['comp.sys.ibm.pc.hardware','comp.sys.mac.hardware','misc.forsale','soc.religion.christian']\n",
    "\n",
    "for category in list:\n",
    "    categories = [category]\n",
    "    sub_data = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)\n",
    "    TFxIDF_sub = TfidfVectorizer(analyzer='word',max_features=10, stop_words=stop_words,token_pattern='[a-zA-Z]{2,}')\n",
    "    sub_count = TFxIDF_sub.fit_transform(sub_data.data)\n",
    "    #print (sub_count)\n",
    "    print (TFxIDF_sub.vocabulary_.keys())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11669603 -0.01085599  0.10931231 ...,  0.00710093 -0.02644753\n",
      "   0.00926761]\n",
      " [ 0.11314644 -0.09756628  0.01120584 ..., -0.01627233  0.05556114\n",
      "  -0.00143872]\n",
      " [ 0.12020968  0.06752621 -0.01762785 ...,  0.00579854 -0.01355003\n",
      "  -0.00793594]\n",
      " ..., \n",
      " [ 0.06831687 -0.04185763 -0.05470326 ..., -0.01041125 -0.02782422\n",
      "   0.03242747]\n",
      " [ 0.10174729 -0.01898043  0.01056128 ..., -0.03910183  0.00820007\n",
      "   0.04924488]\n",
      " [ 0.12686456 -0.00925992 -0.04837317 ..., -0.01411408 -0.01138661\n",
      "   0.00952479]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "X = TruncatedSVD(n_components=50)\n",
    "LSI = X.fit_transform(TFxIDF_data)\n",
    "print (LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Problem(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "lin_clf = svm.LinearSVC()\n",
    "# print(all_data.target)\n",
    "target_group = [ int(x / 10) for x in all_data.target]\n",
    "# print(target_group)\n",
    "# print(LSI[0])\n",
    "# lin_clf.fit(LSI, all_data.target)\n",
    "lin_clf.fit(LSI, target_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86495808129\n"
     ]
    }
   ],
   "source": [
    "predicted = lin_clf.predict(LSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 50)\n",
      "[1 0 1 0 0 0 1 1 1 1]\n",
      "(18846,)\n",
      "[ 0.47158229 -1.21282766  1.50717892 -1.53937257 -0.8900116  -0.24443776\n",
      "  0.00696778  0.94848737  0.81715432  0.97132677]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = lin_clf.decision_function(LSI)\n",
    "print(LSI.shape)\n",
    "print(predicted[0:10])\n",
    "print(y_score.shape)\n",
    "print(y_score[0:10])\n",
    "fpr, tpr, thresholds = roc_curve(target_group, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC fold (area = %0.2f)' % roc_auc)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8908,  737],\n",
       "       [1092, 8109]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_group, predicted_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49497014  0.49494297  0.4949696   0.49499623  0.49502287  0.4950495\n",
      "  0.49507614  0.49510279  0.49512943  0.49515608  0.49518273  0.49520939\n",
      "  0.49523604  0.4952627   0.49528937  0.49531603  0.4953427   0.49536937\n",
      "  0.49539605  0.49542272  0.4954494   0.49547609  0.49550277  0.49552946\n",
      "  0.49555615  0.49558285  0.49560955  0.49563625  0.49566295  0.49568966\n",
      "  0.49571636  0.49574308  0.49576979  0.49579651  0.49582323  0.49584995\n",
      "  0.49587668  0.49590341  0.49593014  0.49595687  0.49598361  0.49601035\n",
      "  0.49603709  0.49606384  0.49609059  0.49611734  0.4961441   0.49617086\n",
      "  0.49619762  0.49622438  0.49625115  0.49627792  0.49630469  0.49633146\n",
      "  0.49635824  0.49638502  0.49641181  0.49643859  0.49646538  0.49649217\n",
      "  0.49651897  0.49654577  0.49657257  0.49659937  0.49662618  0.49665299\n",
      "  0.4966798   0.49670662  0.49673344  0.49676026  0.49678708  0.49681391\n",
      "  0.49684074  0.49686757  0.4968404   0.49686724  0.49689407  0.49692092\n",
      "  0.49694776  0.49697461  0.49700146  0.49702831  0.49705517  0.49708203\n",
      "  0.49710889  0.49713575  0.49716262  0.49718949  0.49721637  0.49724324\n",
      "  0.49727012  0.49729701  0.49732389  0.49735078  0.49737767  0.49740456\n",
      "  0.49743146  0.49745836  0.49748526  0.49751217]\n",
      "[ 1.          0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132  0.99989132\n",
      "  0.99989132  0.99989132  0.99978263  0.99978263  0.99978263  0.99978263\n",
      "  0.99978263  0.99978263  0.99978263  0.99978263  0.99978263  0.99978263\n",
      "  0.99978263  0.99978263  0.99978263  0.99978263  0.99978263  0.99978263\n",
      "  0.99978263  0.99978263  0.99978263  0.99978263  0.99978263  0.99978263\n",
      "  0.99978263  0.99978263  0.99978263  0.99978263]\n"
     ]
    }
   ],
   "source": [
    "##### from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "precision, recall, _ = precision_recall_curve(target_group,y_score)\n",
    "average_precision = average_precision_score(target_group, y_score)\n",
    "print (precision[0:100])\n",
    "print (recall[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
